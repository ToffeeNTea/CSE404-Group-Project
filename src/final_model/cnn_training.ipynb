{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51ceeca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import resnet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import sys\n",
    "sys.modules['Image'] = Image \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b34467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals   \n",
    "path_to_data_dir = \"../../database/sorted_by_state/\"\n",
    "test_file = \"Arkansas/_09TL3yHwqMzcB8m4BUGoQ.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "736a82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = ImageDataGenerator(rescale=1./255, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "34009be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 834 images belonging to 1 classes.\n",
      "Found 208 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data.flow_from_directory(path_to_data_dir, target_size=(224, 224), batch_size=64, class_mode='categorical', shuffle=True, subset=\"training\")\n",
    "validation_dataset = data.flow_from_directory(path_to_data_dir, target_size=(224, 224), batch_size=64, class_mode='categorical', shuffle=False, subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8593306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 3 convolution layers max pooled 3 times with relu as activation function and softmax applied to output layer\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), activation='relu', use_bias=True),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation='relu', use_bias=True),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=[\n",
    "              tf.keras.metrics.Accuracy(),\n",
    "              tf.keras.metrics.Recall(),\n",
    "              tf.keras.metrics.Precision(),\n",
    "              tf.keras.metrics.F1Score(),\n",
    "            ],\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7851233b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected all entries in the `metrics` list to be metric objects. Received instead:\nmetrics=[['accuracy'], ['f1score'], ['precision'], ['recall']]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 27\u001b[39m\n\u001b[32m     22\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mModel weights saved at epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfn\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     25\u001b[39m custom_callback = CustomClallback(epochs_to_save=epochs_to_save)\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m model_fit = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs_to_save\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m#+1 to include the last epoch\u001b[39;49;00m\n\u001b[32m     29\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcustom_callback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     31\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epochs_to_save:\n\u001b[32m     34\u001b[39m     fn = \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.keras\u001b[39m\u001b[33m'\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\School\\MSU Sm 5\\CSE-404\\CSE404-Group-Project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\School\\MSU Sm 5\\CSE-404\\CSE404-Group-Project\\.venv\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py:237\u001b[39m, in \u001b[36mCompileMetrics._build_metrics_set\u001b[39m\u001b[34m(self, metrics, num_outputs, output_names, y_true, y_pred, argument_name)\u001b[39m\n\u001b[32m    235\u001b[39m             metrics = [metrics]\n\u001b[32m    236\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(is_function_like(m) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics):\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    238\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mExpected all entries in the `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m` list \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    239\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mto be metric objects. Received instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    240\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00margument_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetrics\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    241\u001b[39m             )\n\u001b[32m    242\u001b[39m         flat_metrics.append(\n\u001b[32m    243\u001b[39m             MetricsList(\n\u001b[32m    244\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    249\u001b[39m             )\n\u001b[32m    250\u001b[39m         )\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Expected all entries in the `metrics` list to be metric objects. Received instead:\nmetrics=[['accuracy'], ['f1score'], ['precision'], ['recall']]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "epochs_to_save = [1,2]\n",
    "model_version= \"v1.0\"\n",
    "\n",
    "save_dir = \"saved_models/\"\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "class CustomClallback(Callback):\n",
    "    def __init__(self, epochs_to_save):\n",
    "        super().__init__()\n",
    "        self.epochs_to_save = epochs_to_save\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch in self.epochs_to_save:\n",
    "            fn = f'{model_version}_{epoch:02d}.keras'\n",
    "\n",
    "            # Save the model weights\n",
    "            self.model.save(save_dir + fn)\n",
    "            print(f\"Model weights saved at epoch {epoch} to {fn}\")\n",
    "\n",
    "\n",
    "custom_callback = CustomClallback(epochs_to_save=epochs_to_save)\n",
    "\n",
    "model_fit = model.fit(train_dataset, \n",
    "                    epochs=epochs_to_save[-1] + 1, #+1 to include the last epoch\n",
    "                    validation_data=validation_dataset,\n",
    "                    callbacks=[custom_callback],\n",
    "                    )\n",
    "\n",
    "for epoch in epochs_to_save:\n",
    "    fn = f'{model_version}_{epoch:02d}.keras'\n",
    "    model.load_weights(save_dir + fn)\n",
    "\n",
    "    # Evaluate the model on the validation dataset\n",
    "    loss, accuracy = model.evaluate(validation_dataset)\n",
    "    print(f\"Model {fn} - Validation Loss: {loss}, Validation Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
