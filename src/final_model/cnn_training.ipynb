{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ceeca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import resnet50\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b34467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals   \n",
    "path_to_data_dir = \"../../database/sorted_by_state/\"\n",
    "test_file = \"Alabama/_BK45Fzhx9-uhaBc8M77Eg.jpeg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "736a82ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imread(path_to_data_dir + test_file).shape\n",
    "train = ImageDataGenerator(rescale=1./255)\n",
    "validation = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "34009be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51175 images belonging to 54 classes.\n",
      "Found 51175 images belonging to 54 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = train.flow_from_directory(path_to_data_dir, target_size=(224, 224), batch_size=64, class_mode='categorical', shuffle=True)\n",
    "validation_dataset = train.flow_from_directory(path_to_data_dir, target_size=(224, 224), batch_size=64, class_mode='categorical', shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b8593306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model with 3 convolution layers max pooled 3 times with relu as activation function and softmax applied to output layer\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=16, kernel_size=(3, 3), strides=(1, 1), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), strides=(1, 1), activation='relu', use_bias=True),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), activation='relu', use_bias=True),\n",
    "    tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=None, padding='valid'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "              optimizer=RMSprop(learning_rate=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7851233b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import PIL.Image. The use of `load_img` requires PIL.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[43]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m model_fit = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalidation_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\School\\MSU Sm 5\\CSE-404\\CSE404-Group-Project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32mf:\\School\\MSU Sm 5\\CSE-404\\CSE404-Group-Project\\.venv\\Lib\\site-packages\\keras\\src\\utils\\image_utils.py:227\u001b[39m, in \u001b[36mload_img\u001b[39m\u001b[34m(path, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Loads an image into PIL format.\u001b[39;00m\n\u001b[32m    196\u001b[39m \n\u001b[32m    197\u001b[39m \u001b[33;03mExample:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    224\u001b[39m \u001b[33;03m    A PIL Image instance.\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    226\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pil_image \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m227\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m    228\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not import PIL.Image. The use of `load_img` requires PIL.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    229\u001b[39m     )\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, io.BytesIO):\n\u001b[32m    231\u001b[39m     img = pil_image.open(path)\n",
      "\u001b[31mImportError\u001b[39m: Could not import PIL.Image. The use of `load_img` requires PIL."
     ]
    }
   ],
   "source": [
    "model_fit = model.fit(train_dataset, epochs=2, validation_data=validation_dataset, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
